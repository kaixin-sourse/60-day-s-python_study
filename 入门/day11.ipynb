{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数优化------网格搜索和贝叶斯优化\n",
    "\n",
    "   今天我们要开始超参数调整的专题了，回归下之前课程说的几个核心知识点\n",
    "模型 = 算法 + 实例化设置的外参（超参数）+训练得到的内参\n",
    "只要调参就需要考2次\n",
    "所以如果不做交叉验证，就需要划分验证集和测试集，但是很多调参方法中都默认有交叉验证，所以实际中可以省去划分验证集和测试集的步骤\n",
    "每个模型都有自己的超参数，每个超参数都有一定的意义。但是如果为了精度和科研 我们完全无需学习。只需要用好调参工具即可\n",
    " 超参数优化是指在机器学习模型训练过程中，通过调整模型的超参数，以提高模型的性能。\n",
    "### 网格搜索：\n",
    " 网格搜索是一种穷举搜索的方法，通过遍历所有可能的参数组合，找到最优的参数组合。（很傻对吧哈哈，但是能得到全局最优解）\n",
    "### 贝叶斯优化：\n",
    " 贝叶斯优化是一种基于概率的优化方法，通过构建概率模型来估计参数的分布，从而找到最优的参数组合。（但是只能得到局部最优解，未必是全局最优解）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
